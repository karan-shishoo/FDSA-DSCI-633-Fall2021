{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIT DSCI-633: Foundations of Data Science and Analytics\n",
    "## Assignment 2\n",
    "### Due: 11:59 pm EST, Saturday, Oct 30, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (20 points)\n",
    "\n",
    "**(Use no more than a word, phrase or a sentence to answer these questions)**\n",
    "\n",
    "1.\tTrue or False: When building a classification model, our goal is to minimize the test error.\n",
    "2.\tName two reasons to build a classification model.\n",
    "3.\tTrue or False:  The decision tree built recursively by choosing the best split at each node can be shown to be optimal.\n",
    "4.\tGiven a categorical attribute that can take n different values, how many binary splits are possible ? Does the answer depending on whether it is ordinal vs nominal ?\n",
    "5.\tA numeric attribute can have infinitely many values, but let us say it has n unique values in the training data. How many binary splits do we need to consider in practice ?\n",
    "6.\tUnder what condition is the impurity of a node the maximum (assuming an N-class problem) ?\n",
    "7.\tTrue or False: The entropy of the child nodes of a given node is the sum of their entropy.\n",
    "8.\tWhy do we use Gain Ratio rather than Gain to decide on the best split of a decision tree node ?\n",
    "9.\tName two generic strategies to prevent a decision tree from overfitting the training data.\n",
    "10.\tThe decision boundaries learned by decision trees are constrained to be ___________ in shape.\n",
    "11.\tName two advantages of using k-fold cross-validation over holdout for model evaluation.\n",
    "12.\tHow do model hyperparameters differ from model parameters ? And how are they optimized ?\n",
    "13.\tOn my summer internship, I trained an OCR (optical character recognition) model using a large training set and evaluated its performance on a test dataset of 1000 samples of handwritten characters. The classifier was 99.8% accurate; it only made 2 errors on the test set. I visually inspected the misclassified test samples and found that by adjusting the image binarization settings, I could get a 100% accuracy on the test set. The next morning, I reported my results to my supervisor who happened to be a data scientist. She was very _________. (select “pleased” or “unhappy”, and explain why). \n",
    "14.\tI would like to report the accuracy of a classifier using a confidence interval. \n",
    "True or False: In order to have greater confidence in its reported accuracy, I should test it on a larger test set, or use a narrower confidence interval.\n",
    "15.\tWe find that using a certain model, the test error is large. \n",
    "True or False: This clearly suggests that the model is overfitting the training data.\n",
    "16.\tName two interconnected factors that contribute to model overfitting.\n",
    "17.\tTrue or false: Model selection refers to the problem of selecting the most appropriate classification technique to apply to the problem.\n",
    "18.\tName two generic approaches for model selection.\n",
    "19.\tExplain in brief, the difference between Pessimistic and Optimistic error estimates for a decision tree.\n",
    "20.\tName one advantage and one disadvantage of post-pruning vs pre-pruning a decision tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8.\n",
    "\n",
    "9.\n",
    "\n",
    "10.\n",
    "\n",
    "11.\n",
    "\n",
    "12.\n",
    "\n",
    "13.\n",
    "\n",
    "14.\n",
    "\n",
    "15.\n",
    "\n",
    "16.\n",
    "\n",
    "17.\n",
    "\n",
    "18.\n",
    "\n",
    "19.\n",
    "\n",
    "20.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (20 points)\n",
    "\n",
    "Consider the training examples shown in the table below for a binary classification problem.\n",
    "\n",
    "\n",
    "| Cust ID | Gender | Car Type | Shirt Size | Income | Class |\n",
    "|---|---|---|---|---|---|\n",
    "| 1 | M | Family | Small | 70 | C0 |\n",
    "| 2 | M | Sports | Medium | 110 | C0 |\n",
    "| 3 | M | Sports | Medium | 80 | C0 |\n",
    "| 4 | M | Sports | Large | 80 | C0 |\n",
    "| 5 | M | Sports | Extra Large | 200 | C0 |\n",
    "| 6 | M | Sports | Extra Large | 150 | C0 |\n",
    "| 7 | F | Sports | Small | 130 | C0 |\n",
    "| 8 | F | Sports | Small | 90 | C0 |\n",
    "| 9 | F | Sports | Medium | 100 | C0 |\n",
    "| 10 | F | Luxury | Large | 120 | C0 |\n",
    "| 11 | M | Family | Large | 150 | C1 |\n",
    "| 12 | M | Family | Extra Large | 140 | C1 |\n",
    "| 13 | M | Family | Medium | 90 | C1 |\n",
    "| 14 | M | Luxury | Extra Large | 200 | C1 |\n",
    "| 15 | F | Luxury | Small | 190 | C1 |\n",
    "| 16 | F | Luxury | Small | 130 | C1 |\n",
    "| 17 | F | Luxury | Medium | 150 | C1 |\n",
    "| 18 | F | Luxury | Medium | 180 | C1 |\n",
    "| 19 | F | Luxury | Medium | 80 | C1 |\n",
    "| 20 | F | Luxury | Large | 190 | C1 |\n",
    "\n",
    "\n",
    "\n",
    "**2.1.**\tCompute all three Impurity Measures (Gini index, Entropy and Classification Error Rate) for the overall collection of training examples.\n",
    "\n",
    "**2.2.**\tWe are considering splitting the root node based on each of the following attributes:  Gender, Car Type, Shirt Size and Income.\n",
    "\n",
    "For each categorical attribute, we would like to explore just one multi-way split with as many children as there are values.\n",
    "For numeric attributes, we would like to explore all possible binary splits.\n",
    "\n",
    "For each split above, compute all three Impurity Measures after the split. \n",
    "\n",
    "For each split above, compute the Gain based on each Impurity Measure.\n",
    "\n",
    "**2.3.**\tWhich split (across all attributes) is best according to the Gain based on each impurity measure ?\n",
    "\n",
    "**2.4.**\tWhat is the training error rate of the simple tree induced by this best split ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 (25 points)\n",
    "\n",
    "**(Use no more than a word, phrase or a sentence to answer these questions)**\n",
    "\n",
    "1.\tName the primary difference between a generative and discriminative classifier.\n",
    "2.\tTrue or False: A decision tree is a non-linear classifier.\n",
    "3.\tYou are asked to design a k-NN classifier. How would you optimize the value of k ?\n",
    "4.\tYour colleague has implemented a k-NN classification function in Python to classify email messages. You would like to use the code on your dataset to classify hospital patients. What may you need to change ?\n",
    "5.\tWhy is the nearest neighbor classifier called a “lazy learner” ?\n",
    "6.\tNaïve Bayes is a generative classifier. Why ?\n",
    "7.\tState the major assumption Naïve Bayes makes about the input attributes.\n",
    "8.\tTrue or False: Bagging involves combining the decisions of classifiers build on small subsets of training data called “bootstrap samples” that are selected at random without replacement.\n",
    "9.\tTrue or False: Every tree in a Random Forest uses the full set of the available attributes on a random subset of training data samples.\n",
    "10.\tCan the generalization error of Random Forest be estimated without an explicit test set ?\n",
    "11.\tTrue or False: Artificial Neural Networks closely model the processing of information in mammalian brains.\n",
    "12.\tWhat is meant by a “fully connected layer” in an ANN ?\n",
    "13.\tTrue or False:  ANNs are able to model highly non-linear functions from input features to output classes primarily because they distribute computation over a large number of artificial neurons.\n",
    "14.\tWhat is the role of softmax activation in ANNs ?\n",
    "15.\tYou have been asked to design an ANN for a classification problem. Assuming the input has N numeric attributes, how many neurons should you have in the input layer ? And in the output layer ?\n",
    "16.\tWhat is meant by “one-hot” encoding of a categorical value ?\n",
    "17.\tName the algorithm used for training an ANN (which uses the aggregate loss on a batch of training samples to update all of the weights).\n",
    "18.\tHow can we ensure that ANN training converges to the global minimum in the loss surface ?\n",
    "19.\tName two common types of Deep Networks.\n",
    "20. Name one reason why Deep Networks may not be a good choice for given classification problem.\n",
    "21. What is Gradient Descent ?\n",
    "22.\tTrue or False: Logistic Regression constructs decision boundaries in the shape of a sigmoid curve.\n",
    "23. True or False: Redundant attributes can post a problem for Logistic Regression.\n",
    "24. State the primary assumption made by Logistic Regression and compare it to Naive Bayes.\n",
    "25.\tName one reason Logistic Regression is popular despite not being as powerful as other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8.\n",
    "\n",
    "9.\n",
    "\n",
    "10.\n",
    "\n",
    "11.\n",
    "\n",
    "12.\n",
    "\n",
    "13.\n",
    "\n",
    "14.\n",
    "\n",
    "15.\n",
    "\n",
    "16.\n",
    "\n",
    "17.\n",
    "\n",
    "18.\n",
    "\n",
    "19.\n",
    "\n",
    "20.\n",
    "\n",
    "21.\n",
    "\n",
    "22.\n",
    "\n",
    "23.\n",
    "\n",
    "24.\n",
    "\n",
    "25.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (15 points)\n",
    "\n",
    "Assuming the training dataset in Problem 2, and ignoring the Cust ID attribute, classify the following data points as being class C0 or C1 using the Naive Bayes classifier:\n",
    "\n",
    "(Gender = M, Car Type = Family, Shirt Size = Small, Income = 110 )\n",
    "\n",
    "(Gender = F, Car Type = Luxury, Shirt Size = Female, Income = 90)\n",
    "\n",
    "(Gender = M, Car Type = Sports, Shirt Size = Extra Large, Income = 140)\n",
    "\n",
    "Assume that income is quantized using five intervals (< 90, 91-120, 121-150, 151-180, > 180) for the purposes of applying Naive Bayes.\n",
    "\n",
    "Show your work and the class probabilities computed by Naive Bayes.\n",
    "\n",
    "**Extra credit (5 points):** How does the above change if you were to model income using a Normal Distribution instead of using quantization ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 (10 points)\n",
    "\n",
    "Download the ‘Diamonds’ dataset from https://www.kaggle.com/shivam2503/diamonds.\n",
    "\n",
    "**5.1.** Design and implement as a Python function, what you feel is a good proximity measure between two data samples (diamonds) in the Diamonds dataset. Explain the rationale for your design.\n",
    "\n",
    "**5.2.** Implement a function that takes the index of a data sample in the dataset as input, and returns the indices of its k nearest neighbors using the proximity measure you defined, where k is a parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6 (20 points)\n",
    "\n",
    "Download the Indian Liver Patient Dataset from https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset). This dataset contains data about two types of patients - those with, and without liver disease. All but one attribute are continuous.\n",
    "\n",
    "\n",
    "**6.1.**\tExploratory analysis and Preprocessing\n",
    "\n",
    "a.\tCompute the distribution of the classes\n",
    "\n",
    "b.\tCheck if any of the data samples have missing values, and if so, replace them with appropriate imputed values\n",
    "\n",
    "c.\tReplace the categorical attribute with multiple binary attributes using one-hot encoding.\n",
    "\n",
    "d. Plot the correlation between all pairs of attributes (including the class attribute)\n",
    "\n",
    "e.\tDivide the data randomly into a training, validation dataset and a test dataset in a 70:10:20 ratio.\n",
    "\n",
    "**6.2.**\tDecision Tree Classifier\n",
    "\n",
    "a.\tTrain a Decision Tree classifier on the training data using Gini Index as the impurity measure.\n",
    "\n",
    "b.\tCompute the classification accuracy on the training and validation data.\n",
    "\n",
    "c.\tTry alternative values for any one hyperparameter of your choice and see if the validation accuracy improves. \n",
    "\n",
    "d. Compute the test accuracy for the best setting of the hyperparameter and plot the confusion matrix.\n",
    "\n",
    "**6.3.**\tK-NN\n",
    "\n",
    "a.\tUse k-NN with Euclidean distance and k = 5.\n",
    "\n",
    "b.\tCompute the classification accuracy on the training, validation and test data.\n",
    "\n",
    "c.\tTry alternative values of k (such as 1, 3, 7, 9) and see if the validation accuracy improves. \n",
    "\n",
    "d. Compute the test accuracy for the best setting of k and plot the confusion matrix.\n",
    "\n",
    "e.\tRepeat steps b, c and d after normalizing the input features\n",
    "\n",
    "\n",
    "**6.4.**\tCross-validation\n",
    "\n",
    "a.\tUse 5-fold cross-validation to train and evaluate the decision tree and k-NN classifiers on the entire dataset, using 4 folds for training and one for testing. Ideally we would use nested validation to select hyper parameters, but you can use the hyper-parameter values selected earlier.\n",
    "\n",
    "\n",
    "**6.5.**\tOther classifiers\n",
    "\n",
    "a.\tUse cross validation to compare the results of any one of Random Forest, Logistic Regression, or ANN for this problem and with those of Decision Tree and k-NN.\n",
    "\n",
    "**Extra credit (5 points):** Attempt additional exploratory analysis and preprocessing to improve the validation accuracy.\n",
    "\n",
    "\n",
    "**Extra credit (5 points):** Instead of a fixed validation set, split the dataset into a training and test set in a 80:20 ratio and use the GridSearchCV function on the training set to look for the best hyperpamater values for Decision tree and k-NN classification. Compute the accuracy using the best performing hyperparameters using 5-fold cross-validation on the entire dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission instructions\n",
    "\n",
    "1. Your assignment should be completed by filling in the empty solution cells in this Jupyter notebook file (.ipynb). Feel free to add more cells as needed.\n",
    "\n",
    "2. Please comment your code using either markdown or #comments and use meaningful variable names to make it as readable and intelligible as possible.\n",
    "\n",
    "3. Write your code in the form of functions. For example: \n",
    "\n",
    "    def my_code ():\n",
    "\n",
    "          #Write code here\n",
    "      \n",
    "          return \"The return value\"\n",
    "          \n",
    "\n",
    "4. If the problem is to find the value of 'x', printing 'x = (your answer)' will help us identify if your code worked.\n",
    "\n",
    "\n",
    "5. For code that refers to local data files downloaded from the internet, please keep the file path simple (e.g. ~/downloads/datafilename) so that it works on our copy of the dataset. Please do not modify either the filename or the file contents in any way.\n",
    "\n",
    "6. Solution to problems that do not require any coding can be typed up in their own cells using markdown.\n",
    "    \n",
    "7. Unless there are legitimate circumstances, late assignments will not be accepted.\n",
    "\n",
    "8. All assignments are individual.\n",
    "\n",
    "9. All the sources used for problem solution must be acknowledged, e.g. web sites, books, research papers, etc.\n",
    "\n",
    "10. Academic integrity is taken seriously; for detailed information see the RIT Honor Code and with RIT's Academic Integrity Policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
